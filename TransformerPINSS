{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9246978,"sourceType":"datasetVersion","datasetId":5593943},{"sourceId":9247003,"sourceType":"datasetVersion","datasetId":5593960},{"sourceType":"kernelVersion","sourceId":194069625}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install numpy matplotlib tqdm torch scipy \n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport matplotlib.pyplot as plt\nimport random\nfrom torch.optim import LBFGS, Adam\nfrom tqdm import tqdm\nimport scipy.io\n\nfrom utility_py import *","metadata":{"execution":{"iopub.status.busy":"2024-08-25T23:56:07.899781Z","iopub.execute_input":"2024-08-25T23:56:07.900663Z","iopub.status.idle":"2024-08-25T23:56:20.701174Z","shell.execute_reply.started":"2024-08-25T23:56:07.900621Z","shell.execute_reply":"2024-08-25T23:56:20.700035Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.26.4)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (3.7.5)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.66.4)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (1.14.0)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (9.5.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"seed = 0\nnp.random.seed(seed)\nrandom.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\n\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n# If using GPU, also set seeds for CUDA\nif device.type == 'cuda':\n    torch.cuda.manual_seed(seed)\nprint(f\"Using device: {device}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-25T23:56:20.704116Z","iopub.execute_input":"2024-08-25T23:56:20.704925Z","iopub.status.idle":"2024-08-25T23:56:20.715231Z","shell.execute_reply.started":"2024-08-25T23:56:20.704875Z","shell.execute_reply":"2024-08-25T23:56:20.714277Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Using device: cuda:0\n","output_type":"stream"}]},{"cell_type":"code","source":"data = scipy.io.loadmat('/kaggle/input/cylinder-nektar-wake-mat/cylinder_nektar_wake.mat')","metadata":{"execution":{"iopub.status.busy":"2024-08-25T23:56:20.716534Z","iopub.execute_input":"2024-08-25T23:56:20.716932Z","iopub.status.idle":"2024-08-25T23:56:20.750935Z","shell.execute_reply.started":"2024-08-25T23:56:20.716887Z","shell.execute_reply":"2024-08-25T23:56:20.750075Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"U_star = data['U_star'] # N x 2 x T\nP_star = data['p_star'] # N x T\nt_star = data['t'] # T x 1\nX_star = data['X_star'] # N x 2\n\nN = X_star.shape[0]\nT = t_star.shape[0]\n\n# Rearrange Data \nXX = np.tile(X_star[:,0:1], (1,T)) # N x T\nYY = np.tile(X_star[:,1:2], (1,T)) # N x T\nTT = np.tile(t_star, (1,N)).T # N x T\n\nUU = U_star[:,0,:] # N x T\nVV = U_star[:,1,:] # N x T\nPP = P_star # N x T\n\nx = XX.flatten()[:,None] # NT x 1\ny = YY.flatten()[:,None] # NT x 1\nt = TT.flatten()[:,None] # NT x 1\n\nu = UU.flatten()[:,None] # NT x 1\nv = VV.flatten()[:,None] # NT x 1\np = PP.flatten()[:,None] # NT x 1\n\nidx = np.random.choice(N*T,2500, replace=False)\nx_train = x[idx,:]\ny_train = y[idx,:]\nt_train = t[idx,:]\nu_train = u[idx,:]\nv_train = v[idx,:]\n\nx_train = torch.tensor(x_train, dtype=torch.float32, requires_grad=True).to(device)\ny_train = torch.tensor(y_train, dtype=torch.float32, requires_grad=True).to(device)\nt_train = torch.tensor(t_train, dtype=torch.float32, requires_grad=True).to(device)\nu_train = torch.tensor(u_train, dtype=torch.float32, requires_grad=True).to(device)\nv_train = torch.tensor(v_train, dtype=torch.float32, requires_grad=True).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-08-25T23:56:20.752322Z","iopub.execute_input":"2024-08-25T23:56:20.752831Z","iopub.status.idle":"2024-08-25T23:56:20.812512Z","shell.execute_reply.started":"2024-08-25T23:56:20.752771Z","shell.execute_reply":"2024-08-25T23:56:20.811513Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"class QRes_block(nn.Module):\n    def __init__(self, in_dim, out_dim):\n        super(QRes_block, self).__init__()\n        self.H1 = nn.Linear(in_features=in_dim, out_features=out_dim)\n        self.H2 = nn.Linear(in_features=in_dim, out_features=out_dim)\n        self.act = nn.Sigmoid()\n    \n    def forward(self, x):\n        x1 = self.H1(x)\n        x2 = self.H2(x)\n        return self.act(x1*x2 + x1)\n\n\n\nclass QRes(nn.Module):\n    def __init__(self, in_dim, hidden_dim, out_dim, num_layer):\n        super(QRes, self).__init__()\n        self.N = num_layer-1\n        self.inlayer = QRes_block(in_dim, hidden_dim)\n        self.layers = get_clones(QRes_block(hidden_dim, hidden_dim), num_layer-1)\n        self.outlayer = nn.Linear(in_features=hidden_dim, out_features=out_dim)\n\n    def forward(self, x,y,t):\n        src = torch.cat((x,y,t), dim=-1)\n        src = self.inlayer(src)\n        for i in range(self.N):\n            src = self.layers[i](src)\n        src = self.outlayer(src)\n        return src\n    \n\ndef init_weights(m):\n    if isinstance(m, nn.Linear):\n        torch.nn.init.xavier_uniform(m.weight)\n        m.bias.data.fill_(0.01)","metadata":{"execution":{"iopub.status.busy":"2024-08-25T23:56:20.816008Z","iopub.execute_input":"2024-08-25T23:56:20.816457Z","iopub.status.idle":"2024-08-25T23:56:20.826937Z","shell.execute_reply.started":"2024-08-25T23:56:20.816416Z","shell.execute_reply":"2024-08-25T23:56:20.825851Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"model = QRes(in_dim=3, hidden_dim=256, out_dim=2, num_layer=4).to(device)\n\nmodel.apply(init_weights)\noptim = LBFGS(model.parameters(), line_search_fn='strong_wolfe')\n# optim = Adam(model.parameters(), lr=1e-3)\n\nprint(model)\nprint(get_n_params(model))","metadata":{"execution":{"iopub.status.busy":"2024-08-25T23:56:20.828097Z","iopub.execute_input":"2024-08-25T23:56:20.828407Z","iopub.status.idle":"2024-08-25T23:56:20.848361Z","shell.execute_reply.started":"2024-08-25T23:56:20.828375Z","shell.execute_reply":"2024-08-25T23:56:20.847496Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"QRes(\n  (inlayer): QRes_block(\n    (H1): Linear(in_features=3, out_features=256, bias=True)\n    (H2): Linear(in_features=3, out_features=256, bias=True)\n    (act): Sigmoid()\n  )\n  (layers): ModuleList(\n    (0-2): 3 x QRes_block(\n      (H1): Linear(in_features=256, out_features=256, bias=True)\n      (H2): Linear(in_features=256, out_features=256, bias=True)\n      (act): Sigmoid()\n    )\n  )\n  (outlayer): Linear(in_features=256, out_features=2, bias=True)\n)\n397314\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/1630523777.py:34: FutureWarning: `nn.init.xavier_uniform` is now deprecated in favor of `nn.init.xavier_uniform_`.\n  torch.nn.init.xavier_uniform(m.weight)\n","output_type":"stream"}]},{"cell_type":"code","source":"loss_track = []\n\nfor i in tqdm(range(1000)):\n    def closure():\n        psi_and_p = model(x_train, y_train, t_train)\n        psi = psi_and_p[:,0:1]\n        p = psi_and_p[:,1:2]\n\n        u = torch.autograd.grad(psi, y_train, grad_outputs=torch.ones_like(psi), retain_graph=True, create_graph=True)[0]\n        v = - torch.autograd.grad(psi, x_train, grad_outputs=torch.ones_like(psi), retain_graph=True, create_graph=True)[0]\n\n        u_t = torch.autograd.grad(u, t_train, grad_outputs=torch.ones_like(u), retain_graph=True, create_graph=True)[0]\n        u_x = torch.autograd.grad(u, x_train, grad_outputs=torch.ones_like(u), retain_graph=True, create_graph=True)[0]\n        u_y = torch.autograd.grad(u, y_train, grad_outputs=torch.ones_like(u), retain_graph=True, create_graph=True)[0]\n        u_xx = torch.autograd.grad(u, x_train, grad_outputs=torch.ones_like(u_x), retain_graph=True, create_graph=True)[0]\n        u_yy = torch.autograd.grad(u, y_train, grad_outputs=torch.ones_like(u_y), retain_graph=True, create_graph=True)[0]\n\n        v_t = torch.autograd.grad(v, t_train, grad_outputs=torch.ones_like(v), retain_graph=True, create_graph=True)[0]\n        v_x = torch.autograd.grad(v, x_train, grad_outputs=torch.ones_like(v), retain_graph=True, create_graph=True)[0]\n        v_y = torch.autograd.grad(v, y_train, grad_outputs=torch.ones_like(v), retain_graph=True, create_graph=True)[0]\n        v_xx = torch.autograd.grad(v, x_train, grad_outputs=torch.ones_like(v_x), retain_graph=True, create_graph=True)[0]\n        v_yy = torch.autograd.grad(v, y_train, grad_outputs=torch.ones_like(v_y), retain_graph=True, create_graph=True)[0]\n\n        p_x = torch.autograd.grad(p, x_train, grad_outputs=torch.ones_like(p), retain_graph=True, create_graph=True)[0]\n        p_y = torch.autograd.grad(p, y_train, grad_outputs=torch.ones_like(p), retain_graph=True, create_graph=True)[0]\n\n        f_u = u_t + (u*u_x + v*u_y) + p_x - 0.01*(u_xx + u_yy) \n        f_v = v_t + (u*v_x + v*v_y) + p_y - 0.01*(v_xx + v_yy)\n\n        loss = torch.mean((u - u_train)**2) + torch.mean((v - v_train)**2) + torch.mean(f_u**2) + torch.mean(f_v**2)\n\n        loss_track.append(loss.item())\n\n        optim.zero_grad()\n        loss.backward()\n        return loss\n\n    optim.step(closure)","metadata":{"execution":{"iopub.status.busy":"2024-08-25T23:56:20.849696Z","iopub.execute_input":"2024-08-25T23:56:20.850146Z","iopub.status.idle":"2024-08-26T00:07:44.902159Z","shell.execute_reply.started":"2024-08-25T23:56:20.850114Z","shell.execute_reply":"2024-08-26T00:07:44.900702Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stderr","text":" 32%|███▏      | 324/1000 [11:23<23:46,  2.11s/it]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[30], line 38\u001b[0m\n\u001b[1;32m     35\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss\n\u001b[0;32m---> 38\u001b[0m \u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/optim/optimizer.py:484\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    480\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    481\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    482\u001b[0m             )\n\u001b[0;32m--> 484\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    487\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/optim/lbfgs.py:437\u001b[0m, in \u001b[0;36mLBFGS.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobj_func\u001b[39m(x, t, d):\n\u001b[1;32m    435\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_directional_evaluate(closure, x, t, d)\n\u001b[0;32m--> 437\u001b[0m     loss, flat_grad, t, ls_func_evals \u001b[38;5;241m=\u001b[39m \u001b[43m_strong_wolfe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_init\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_grad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgtd\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_grad(t, d)\n\u001b[1;32m    441\u001b[0m opt_cond \u001b[38;5;241m=\u001b[39m flat_grad\u001b[38;5;241m.\u001b[39mabs()\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m tolerance_grad\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/optim/lbfgs.py:45\u001b[0m, in \u001b[0;36m_strong_wolfe\u001b[0;34m(obj_func, x, t, d, f, g, gtd, c1, c2, tolerance_change, max_ls)\u001b[0m\n\u001b[1;32m     43\u001b[0m g \u001b[38;5;241m=\u001b[39m g\u001b[38;5;241m.\u001b[39mclone(memory_format\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mcontiguous_format)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# evaluate objective and gradient using initial step\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m f_new, g_new \u001b[38;5;241m=\u001b[39m \u001b[43mobj_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m ls_func_evals \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     47\u001b[0m gtd_new \u001b[38;5;241m=\u001b[39m g_new\u001b[38;5;241m.\u001b[39mdot(d)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/optim/lbfgs.py:435\u001b[0m, in \u001b[0;36mLBFGS.step.<locals>.obj_func\u001b[0;34m(x, t, d)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobj_func\u001b[39m(x, t, d):\n\u001b[0;32m--> 435\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_directional_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/optim/lbfgs.py:289\u001b[0m, in \u001b[0;36mLBFGS._directional_evaluate\u001b[0;34m(self, closure, x, t, d)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_directional_evaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, closure, x, t, d):\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_grad(t, d)\n\u001b[0;32m--> 289\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    290\u001b[0m     flat_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gather_flat_grad()\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_param(x)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[30], line 35\u001b[0m, in \u001b[0;36mclosure\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m loss_track\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m     34\u001b[0m optim\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 35\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/graph.py:768\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    766\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"np.save('./ns_loss_qres.npy', loss_track)\ntorch.save(model.state_dict(), './ns_qres.pt')\n\nloss_track[-1]","metadata":{"execution":{"iopub.status.busy":"2024-08-26T00:07:44.903199Z","iopub.status.idle":"2024-08-26T00:07:44.903550Z","shell.execute_reply.started":"2024-08-26T00:07:44.903376Z","shell.execute_reply":"2024-08-26T00:07:44.903394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" # Test Data\nsnap = np.array([100])\nx_star = X_star[:,0:1]\ny_star = X_star[:,1:2]\nt_star = TT[:,snap]\n\nu_star = U_star[:,0,snap]\nv_star = U_star[:,1,snap]\np_star = P_star[:,snap]\n\nx_star = torch.tensor(x_star, dtype=torch.float32, requires_grad=True).to(device)\ny_star = torch.tensor(y_star, dtype=torch.float32, requires_grad=True).to(device)\nt_star = torch.tensor(t_star, dtype=torch.float32, requires_grad=True).to(device)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-26T00:07:44.904379Z","iopub.status.idle":"2024-08-26T00:07:44.904720Z","shell.execute_reply.started":"2024-08-26T00:07:44.904538Z","shell.execute_reply":"2024-08-26T00:07:44.904555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# with torch.no_grad():\npsi_and_p = model(x_star, y_star, t_star)\npsi = psi_and_p[:,0:1]\np_pred = psi_and_p[:,1:2]\n\nu_pred = torch.autograd.grad(psi, x_star, grad_outputs=torch.ones_like(psi), retain_graph=True, create_graph=True)[0]\nv_pred = - torch.autograd.grad(psi, y_star, grad_outputs=torch.ones_like(psi), retain_graph=True, create_graph=True)[0]\n\nu_pred = u_pred.cpu().detach().numpy()\nv_pred = v_pred.cpu().detach().numpy()\np_pred = p_pred.cpu().detach().numpy()\n\nerror_u = np.linalg.norm(u_star-u_pred,2)/np.linalg.norm(u_star,2)\nerror_v = np.linalg.norm(v_star-v_pred,2)/np.linalg.norm(v_star,2)\nerror_p = np.linalg.norm(p_star-p_pred,2)/np.linalg.norm(p_star,2)","metadata":{"execution":{"iopub.status.busy":"2024-08-26T00:07:44.906293Z","iopub.status.idle":"2024-08-26T00:07:44.906620Z","shell.execute_reply.started":"2024-08-26T00:07:44.906453Z","shell.execute_reply":"2024-08-26T00:07:44.906470Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"error_p","metadata":{"execution":{"iopub.status.busy":"2024-08-26T00:07:44.907795Z","iopub.status.idle":"2024-08-26T00:07:44.908178Z","shell.execute_reply.started":"2024-08-26T00:07:44.908003Z","shell.execute_reply":"2024-08-26T00:07:44.908022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"error_p = np.linalg.norm(p_star-p_pred,1)/np.linalg.norm(p_star,1)\nerror_p","metadata":{"execution":{"iopub.status.busy":"2024-08-26T00:07:44.909382Z","iopub.status.idle":"2024-08-26T00:07:44.909711Z","shell.execute_reply.started":"2024-08-26T00:07:44.909545Z","shell.execute_reply":"2024-08-26T00:07:44.909562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(4,3))\nplt.imshow((p_star).reshape(50,100), extent=[-3,8,-2,2], aspect='auto')\nplt.xlabel('x')\nplt.ylabel('y')\nplt.title('Exact p(x,t)')\nplt.colorbar()\nplt.tight_layout()\nplt.savefig('./ns_exact.png')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-26T00:07:44.910976Z","iopub.status.idle":"2024-08-26T00:07:44.911319Z","shell.execute_reply.started":"2024-08-26T00:07:44.911147Z","shell.execute_reply":"2024-08-26T00:07:44.911164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(4,3))\nplt.imshow((p_pred).reshape(50,100), extent=[-3,8,-2,2], aspect='auto')\nplt.xlabel('x')\nplt.ylabel('y')\nplt.title('Predicted p(x,t)')\nplt.colorbar()\nplt.tight_layout()\nplt.savefig('./ns_qres_pred.png')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-26T00:07:44.912409Z","iopub.status.idle":"2024-08-26T00:07:44.912741Z","shell.execute_reply.started":"2024-08-26T00:07:44.912573Z","shell.execute_reply":"2024-08-26T00:07:44.912590Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(4,3))\nplt.imshow(np.abs(p_pred-p_star).reshape(50,100), extent=[-3,8,-2,2], aspect='auto')\nplt.xlabel('x')\nplt.ylabel('y')\nplt.title('Absolute Error')\nplt.colorbar()\nplt.tight_layout()\nplt.savefig('./ns_qres_error.png')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-26T00:07:44.914222Z","iopub.status.idle":"2024-08-26T00:07:44.914572Z","shell.execute_reply.started":"2024-08-26T00:07:44.914391Z","shell.execute_reply":"2024-08-26T00:07:44.914409Z"},"trusted":true},"execution_count":null,"outputs":[]}]}