{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9143912,"sourceType":"datasetVersion","datasetId":5522806},{"sourceId":9206556,"sourceType":"datasetVersion","datasetId":5566588}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install deepxde tensorflow\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T00:58:00.354005Z","iopub.execute_input":"2024-08-20T00:58:00.354895Z","iopub.status.idle":"2024-08-20T00:58:12.866394Z","shell.execute_reply.started":"2024-08-20T00:58:00.354855Z","shell.execute_reply":"2024-08-20T00:58:12.865145Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Requirement already satisfied: deepxde in /opt/conda/lib/python3.10/site-packages (1.12.0)\nRequirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.15.0)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from deepxde) (3.7.5)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from deepxde) (1.26.4)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from deepxde) (1.2.2)\nRequirement already satisfied: scikit-optimize>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from deepxde) (0.10.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from deepxde) (1.11.4)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (23.5.26)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.10.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (16.0.6)\nRequirement already satisfied: ml-dtypes~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (69.0.3)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.9.0)\nRequirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.14.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.35.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.60.0)\nRequirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.1)\nRequirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.0)\nRequirement already satisfied: keras<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.10/site-packages (from scikit-optimize>=0.9.0->deepxde) (1.4.2)\nRequirement already satisfied: pyaml>=16.9 in /opt/conda/lib/python3.10/site-packages (from scikit-optimize>=0.9.0->deepxde) (24.4.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow) (3.1.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->deepxde) (3.2.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.26.1)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.32.3)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->deepxde) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->deepxde) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->deepxde) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->deepxde) (1.4.5)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->deepxde) (9.5.0)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->deepxde) (2.9.0.post0)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from pyaml>=16.9->scikit-optimize>=0.9.0->deepxde) (6.0.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.7.4)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\n# Set backend\nos.environ[\"DDE_BACKEND\"] = \"tensorflow\"\nimport tensorflow as tf\nimport deepxde as dde\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy.interpolate import interp1d\nfrom scipy.interpolate import RegularGridInterpolator\nfrom deepxde.callbacks import Callback\nimport pandas as pd\n\nBATCH_SIZE = 32  # Batch size\n#LEARNING_RATE = 1e-3  # Learning rate\n\nITERATIONS_A = 20000  # Number of training iterations\nITERATIONS_LBFGS = 20000  # Number of training iterations\nITERATIONS_A2 = 20000  # Number of training iterations\nITERATIONS_LBFGS2 = 10000  # Number of training iterations \n\nT_Start = 0\nTIME_STEP = 0.02\nT_End = 0.02\n# Define the computational domain\ngeom = dde.geometry.Interval(-1, 1)\ntime_domain = dde.geometry.TimeDomain(T_Start, T_End)\ngeomtime = dde.geometry.GeometryXTime(geom, time_domain)\n\n# Define gamma_2 as a trainable variable with an initial value\ngamma_1_AC = tf.Variable(1.0, dtype=tf.float32) # Alpha\ngamma_2_AC = tf.Variable(1.0, dtype=tf.float32, trainable=False) # Kappa \ndef cahn_hilliard(x, y):\n    print(\"Presumed Alpha\")\n    print(gamma_1_AC)\n    dy_t = dde.grad.jacobian(y, x, i=0, j=1)\n    laplacian_u = dde.grad.hessian(y, x, i=0, j=0)\n    laplacian_u_cubed = dde.grad.hessian(y**3, x, i=0, j=0)   # second derivative y^3\n    fourth_derivative_u = dde.grad.hessian(laplacian_u, x, i=0, j=0)\n    return dy_t - gamma_2_AC * (laplacian_u_cubed - laplacian_u - gamma_1_AC * fourth_derivative_u)\n\n# Initial condition Allen Cahn\ndef init_condition_CA(x):\n    return -np.cos(2 * np.pi * x[:, 0:1])\n\n# Initial condition dde for Allen Cahn Equation\ninitial_condition_h_AC = dde.icbc.IC(geomtime, init_condition_CA, lambda _, on_initial: on_initial, component=0)\n\n# Boundary Condition for the Allen-Cahn equation\nbc_h = dde.icbc.PeriodicBC(geomtime, 0, lambda _, on_boundary: on_boundary, derivative_order=0, component=0)\nbc_h_deriv = dde.icbc.PeriodicBC(geomtime, 0, lambda _, on_boundary: on_boundary, derivative_order=1, component=0)\n\n\n# Load the data from the text file\ndata = np.loadtxt('/kaggle/input/output-ch1d/output-CH1d.txt', skiprows=1)\nprint(data)\n# Split the data into spatial coordinates (x), time (t), and solution values (u)\nobserved_x = data[:, 0:1]  # The x column (as 2D array)\nobserved_t = data[:, 1:2]  # The t column (as 2D array)\nobserved_h = data[:, 2:4]  # The solution column (as 2D array)\n# Combine x and t to create the observation points in the space-time domain\nobserved_xt = np.hstack((observed_x, observed_t))\n# Define the PointSetBC using the observed points and solution values\nobserve_h_AC = dde.icbc.PointSetBC(observed_xt, observed_h, component=0)\n\ndata_AC_inverse = dde.data.TimePDE(\n        geomtime,\n        cahn_hilliard,\n        #[bc_h, bc_h_deriv, initial_condition_h_AC],  # Include observe_h here\n        [bc_h, bc_h_deriv, initial_condition_h_AC, observe_h_AC],  # Include observe_h here\n        num_domain=20000,\n        num_boundary=1600,\n        num_initial=4096,\n        anchors=observed_xt,  # Make sure observed_xt is used as anchors if necessary\n        num_test=40000,\n    )\n\n# Your file path\nfile_path = \"kaggle/working/losses_simple.txt\"\n# Check if file exists and delete it\nif os.path.exists(file_path):\n    os.remove(file_path)\n    print(f\"Removed existing file: {file_path}\")\n\nclass SimpleLossTrackingCallback(Callback):\n    def __init__(self, every_n_epochs=1000, file_path=file_path):\n        super(SimpleLossTrackingCallback, self).__init__()\n        self.every_n_epochs = every_n_epochs\n        self.file_path = file_path\n        \n        # Ensure the directory exists\n        os.makedirs(os.path.dirname(self.file_path), exist_ok=True)\n        \n        # Check if file exists and is not empty, if so, skip writing the header\n        if not os.path.exists(self.file_path) or os.stat(self.file_path).st_size == 0:\n            with open(self.file_path, \"w\") as f:\n                f.write(\"Epoch,PDE Loss,BC1 Loss,BC2 Loss,IC Loss,Observe Loss\\n\")\n\n    def on_epoch_end(self):\n        if self.model.train_state.step % self.every_n_epochs == 0 or self.model.train_state.step == 1:\n            current_losses = self.model.train_state.loss_train\n            loss_str = \",\".join(map(str, current_losses))\n            with open(self.file_path, \"a\") as f:\n                f.write(f\"{self.model.train_state.step},{loss_str}\\n\")\n\niterations_list = [0]  # Starting with iteration 0\n\ngamma_1_values = [gamma_1_AC.value().numpy()]  # Assuming this is how you access the value of your variable\ngamma_2_values = [gamma_2_AC.value().numpy()]  # Assuming this is how you access the value of your variable\n\n# Network Architecure\n#net = dde.nn.FNN([2] + [128] * 6 + [1], \"tanh\", \"Glorot normal\")\nnet = dde.nn.FNN([2] + [60] * 4 + [1], \"tanh\", \"Glorot normal\")\nvariable_gamma_1 = dde.callbacks.VariableValue(gamma_1_AC, period=1000)\nvariable_gamma_2 = dde.callbacks.VariableValue(gamma_2_AC, period=1000)\ndetailed_loss_tracker = SimpleLossTrackingCallback()\nmodel = dde.Model(data_AC_inverse, net)\n\nLoss_Weights = [1, 1, 1, 1, 1000]\n\ntotal_iterations = 0\nwhile total_iterations < 60000:\n                # Calculate the number of iterations for this loop\n                iter_this_loop = 1000\n                # Update the total iterations\n                #model.compile(\"adam\", lr=1e-3, loss= 'MSE', loss_weights=Loss_Weights, external_trainable_variables=[gamma_1_AC, gamma_2_AC])\n                #losshistory, train_state = model.train(epochs=70000, display_every=1000, callbacks=[variable_gamma_1, variable_gamma_2, detailed_loss_tracker])\n\n                model.compile(\"adam\", lr=1e-3, loss= 'MSE', loss_weights=Loss_Weights, external_trainable_variables=[gamma_1_AC, gamma_2_AC])\n                losshistory, train_state = model.train(epochs=iter_this_loop, display_every=1000, callbacks=[variable_gamma_1, variable_gamma_2, detailed_loss_tracker])\n                # Update gamma value and error after training\n                current_gamma_1_value = gamma_1_AC.value().numpy()\n                current_gamma_2_value = gamma_2_AC.value().numpy()\n\n                # model.compile(\"L-BFGS\", loss = 'MSE', loss_weights = Loss_Weights, external_trainable_variables=[gamma_2_AC])\n                # losshistory, train_state = model.train(display_every=1000, callbacks=[observed_data_loss_callback, variable])\n\n                # Update gamma value and error after training\n                gamma_1_values.append(current_gamma_1_value)\n                gamma_2_values.append(current_gamma_2_value)\n\n                iterations_list.append(total_iterations + iter_this_loop)\n\n                total_iterations += 1000\n\nplt.figure(figsize=(10, 6))\nplt.plot(iterations_list, gamma_1_values, '-o', label='Iteration vs Gamma Values', color='blue')\nplt.plot(iterations_list, gamma_2_values, '-o', label='Iteration vs Gamma Values', color='red')\nplt.xlabel('Gamma Value', fontsize=14)\nplt.ylabel('Iterations', fontsize=14)\nplt.title('Iterations vs. Gamma Value', fontsize=16)\nplt.legend()\nplt.grid(True, which=\"both\", ls=\"--\")\nplt.show()\n\n\n# Load the losses from the file\nlosses_df = pd.read_csv(file_path)\n\n# Calculate the total loss as the sum of component-wise losses for each iteration\n# Assuming that the first column is 'Epoch' and the rest are loss components\nloss_components = losses_df.columns[1:]  # Exclude 'Epoch'\nlosses_df['Total Loss'] = losses_df[loss_components].sum(axis=1)\n\n# Plotting\nplt.figure(figsize=(10, 6))\n\n# Plot component-wise losses\nfor component in loss_components:\n    plt.plot(losses_df['Epoch'], losses_df[component], label=component)\n\n# Plot total loss\nplt.plot(losses_df['Epoch'], losses_df['Total Loss'], label='Total Loss', color='black', linewidth=2, linestyle='--')\n\nplt.xlabel('Iteration', fontsize=14)\nplt.ylabel('Loss', fontsize=14)\nplt.title('Loss Components and Total Loss over Iterations', fontsize=16)\nplt.legend()\nplt.grid(True)\nplt.yscale('log')  # Use logarithmic scale if desired\n\nplt.show()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-20T00:58:12.868609Z","iopub.execute_input":"2024-08-20T00:58:12.869697Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"[[-1.          0.         -0.97347814  4.68327951]\n [-0.99        0.         -0.97071463  4.68033266]\n [-0.98        0.         -0.96758276  4.6894865 ]\n ...\n [ 0.98        0.02       -0.898314    4.6621666 ]\n [ 0.99        0.02       -0.89778441  4.64194965]\n [ 1.          0.02       -0.89689517  4.63153839]]\nCompiling model...\n'compile' took 0.004005 s\n\nWarning: epochs is deprecated and will be removed in a future version. Use iterations instead.\nTraining model...\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer GlorotNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Presumed Alpha\n<tf.Variable 'Variable:0' shape=() dtype=float32>\nPresumed Alpha\n<tf.Variable 'Variable:0' shape=() dtype=float32>\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1724115500.212687      34 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"Presumed Alpha\n<tf.Variable 'Variable:0' shape=() dtype=float32>\nStep      Train loss                                            Test loss                                             Test metric\n0         [4.48e-01, 6.78e-03, 1.52e-05, 5.01e-01, 5.51e+04]    [4.54e-01, 6.78e-03, 1.52e-05, 5.01e-01, 5.51e+04]    []  \n0 [1.00e+00]\n0 [1.00e+00]\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1724115509.810798      34 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"1000      [3.98e+02, 3.32e-03, 1.35e+01, 4.56e+00, 4.71e+04]    [3.85e+02, 3.32e-03, 1.35e+01, 4.56e+00, 4.71e+04]    []  \n1000 [1.09e-02]\n1000 [1.00e+00]\n\nBest model at step 1000:\n  train loss: 4.75e+04\n  test loss: 4.75e+04\n  test metric: []\n\n'train' took 54.761844 s\n\nCompiling model...\n'compile' took 0.012631 s\n\nWarning: epochs is deprecated and will be removed in a future version. Use iterations instead.\nTraining model...\n\nPresumed Alpha\n<tf.Variable 'Variable:0' shape=() dtype=float32>\nPresumed Alpha\n<tf.Variable 'Variable:0' shape=() dtype=float32>\nStep      Train loss                                            Test loss                                             Test metric\n1000      [3.98e+02, 3.32e-03, 1.35e+01, 4.56e+00, 4.71e+04]    [3.85e+02, 3.32e-03, 1.35e+01, 4.56e+00, 4.71e+04]    []  \n1000 [1.09e-02]\n1000 [1.00e+00]\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1724115557.436761      34 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"2000      [3.60e+02, 2.95e-03, 1.30e+01, 4.66e+00, 4.69e+04]    [3.54e+02, 2.95e-03, 1.30e+01, 4.66e+00, 4.69e+04]    []  \n2000 [6.11e-03]\n2000 [1.00e+00]\n\nBest model at step 2000:\n  train loss: 4.73e+04\n  test loss: 4.73e+04\n  test metric: []\n\n'train' took 47.694074 s\n\nCompiling model...\n'compile' took 0.008194 s\n\nWarning: epochs is deprecated and will be removed in a future version. Use iterations instead.\nTraining model...\n\nPresumed Alpha\n<tf.Variable 'Variable:0' shape=() dtype=float32>\nPresumed Alpha\n<tf.Variable 'Variable:0' shape=() dtype=float32>\nStep      Train loss                                            Test loss                                             Test metric\n2000      [3.60e+02, 2.95e-03, 1.30e+01, 4.66e+00, 4.69e+04]    [3.54e+02, 2.95e-03, 1.30e+01, 4.66e+00, 4.69e+04]    []  \n2000 [6.11e-03]\n2000 [1.00e+00]\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1724115605.144428      34 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"3000      [3.78e+02, 2.47e-03, 1.30e+01, 4.79e+00, 4.68e+04]    [3.62e+02, 2.47e-03, 1.30e+01, 4.79e+00, 4.68e+04]    []  \n3000 [4.91e-03]\n3000 [1.00e+00]\n\nBest model at step 3000:\n  train loss: 4.72e+04\n  test loss: 4.72e+04\n  test metric: []\n\n'train' took 47.700128 s\n\nCompiling model...\n'compile' took 0.012445 s\n\nWarning: epochs is deprecated and will be removed in a future version. Use iterations instead.\nTraining model...\n\nPresumed Alpha\n<tf.Variable 'Variable:0' shape=() dtype=float32>\nPresumed Alpha\n<tf.Variable 'Variable:0' shape=() dtype=float32>\nStep      Train loss                                            Test loss                                             Test metric\n3000      [3.78e+02, 2.47e-03, 1.30e+01, 4.79e+00, 4.68e+04]    [3.62e+02, 2.47e-03, 1.30e+01, 4.79e+00, 4.68e+04]    []  \n3000 [4.91e-03]\n3000 [1.00e+00]\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1724115653.166647      34 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"4000      [3.60e+02, 1.49e-03, 1.30e+01, 4.88e+00, 4.68e+04]    [3.48e+02, 1.49e-03, 1.30e+01, 4.88e+00, 4.68e+04]    []  \n4000 [4.39e-03]\n4000 [1.00e+00]\n\nBest model at step 4000:\n  train loss: 4.72e+04\n  test loss: 4.71e+04\n  test metric: []\n\n'train' took 48.006686 s\n\nCompiling model...\n'compile' took 0.010054 s\n\nWarning: epochs is deprecated and will be removed in a future version. Use iterations instead.\nTraining model...\n\nPresumed Alpha\n<tf.Variable 'Variable:0' shape=() dtype=float32>\nPresumed Alpha\n<tf.Variable 'Variable:0' shape=() dtype=float32>\nStep      Train loss                                            Test loss                                             Test metric\n4000      [3.60e+02, 1.49e-03, 1.30e+01, 4.88e+00, 4.68e+04]    [3.48e+02, 1.49e-03, 1.30e+01, 4.88e+00, 4.68e+04]    []  \n4000 [4.39e-03]\n4000 [1.00e+00]\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1724115700.875609      34 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"5000      [3.82e+02, 1.50e-03, 1.27e+01, 4.89e+00, 4.68e+04]    [3.72e+02, 1.50e-03, 1.27e+01, 4.89e+00, 4.68e+04]    []  \n5000 [4.03e-03]\n5000 [1.00e+00]\n\nBest model at step 4000:\n  train loss: 4.72e+04\n  test loss: 4.71e+04\n  test metric: []\n\n'train' took 47.680252 s\n\nCompiling model...\n'compile' took 0.010526 s\n\nWarning: epochs is deprecated and will be removed in a future version. Use iterations instead.\nTraining model...\n\nPresumed Alpha\n<tf.Variable 'Variable:0' shape=() dtype=float32>\nPresumed Alpha\n<tf.Variable 'Variable:0' shape=() dtype=float32>\nStep      Train loss                                            Test loss                                             Test metric\n5000      [3.82e+02, 1.50e-03, 1.27e+01, 4.89e+00, 4.68e+04]    [3.72e+02, 1.50e-03, 1.27e+01, 4.89e+00, 4.68e+04]    []  \n5000 [4.03e-03]\n5000 [1.00e+00]\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1724115748.483050      34 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"6000      [3.41e+02, 1.36e-03, 1.28e+01, 4.99e+00, 4.67e+04]    [3.31e+02, 1.36e-03, 1.28e+01, 4.99e+00, 4.67e+04]    []  \n6000 [3.76e-03]\n6000 [1.00e+00]\n\nBest model at step 6000:\n  train loss: 4.71e+04\n  test loss: 4.71e+04\n  test metric: []\n\n'train' took 47.611788 s\n\nCompiling model...\n'compile' took 0.007926 s\n\nWarning: epochs is deprecated and will be removed in a future version. Use iterations instead.\nTraining model...\n\nPresumed Alpha\n<tf.Variable 'Variable:0' shape=() dtype=float32>\nPresumed Alpha\n<tf.Variable 'Variable:0' shape=() dtype=float32>\nStep      Train loss                                            Test loss                                             Test metric\n6000      [3.41e+02, 1.36e-03, 1.28e+01, 4.99e+00, 4.67e+04]    [3.31e+02, 1.36e-03, 1.28e+01, 4.99e+00, 4.67e+04]    []  \n6000 [3.76e-03]\n6000 [1.00e+00]\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1724115796.225792      34 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"7000      [3.48e+02, 2.07e-03, 1.26e+01, 5.06e+00, 4.67e+04]    [3.26e+02, 2.07e-03, 1.26e+01, 5.06e+00, 4.67e+04]    []  \n7000 [3.55e-03]\n7000 [1.00e+00]\n\nBest model at step 7000:\n  train loss: 4.71e+04\n  test loss: 4.70e+04\n  test metric: []\n\n'train' took 47.731370 s\n\nCompiling model...\n'compile' took 0.008295 s\n\nWarning: epochs is deprecated and will be removed in a future version. Use iterations instead.\nTraining model...\n\nPresumed Alpha\n<tf.Variable 'Variable:0' shape=() dtype=float32>\nPresumed Alpha\n<tf.Variable 'Variable:0' shape=() dtype=float32>\nStep      Train loss                                            Test loss                                             Test metric\n7000      [3.48e+02, 2.07e-03, 1.26e+01, 5.06e+00, 4.67e+04]    [3.26e+02, 2.07e-03, 1.26e+01, 5.06e+00, 4.67e+04]    []  \n7000 [3.55e-03]\n7000 [1.00e+00]\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1724115843.849765      34 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"8000      [4.95e+02, 3.04e-03, 1.24e+01, 5.16e+00, 4.67e+04]    [5.00e+02, 3.04e-03, 1.24e+01, 5.16e+00, 4.67e+04]    []  \n8000 [3.52e-03]\n8000 [1.00e+00]\n\nBest model at step 7000:\n  train loss: 4.71e+04\n  test loss: 4.70e+04\n  test metric: []\n\n'train' took 47.507781 s\n\nCompiling model...\n'compile' took 0.009028 s\n\nWarning: epochs is deprecated and will be removed in a future version. Use iterations instead.\nTraining model...\n\nPresumed Alpha\n<tf.Variable 'Variable:0' shape=() dtype=float32>\nPresumed Alpha\n<tf.Variable 'Variable:0' shape=() dtype=float32>\nStep      Train loss                                            Test loss                                             Test metric\n8000      [4.95e+02, 3.04e-03, 1.24e+01, 5.16e+00, 4.67e+04]    [5.00e+02, 3.04e-03, 1.24e+01, 5.16e+00, 4.67e+04]    []  \n8000 [3.52e-03]\n8000 [1.00e+00]\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1724115891.902709      34 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"9000      [5.27e+02, 4.58e-03, 1.21e+01, 5.20e+00, 4.67e+04]    [4.88e+02, 4.58e-03, 1.21e+01, 5.20e+00, 4.67e+04]    []  \n9000 [3.27e-03]\n9000 [1.00e+00]\n\nBest model at step 7000:\n  train loss: 4.71e+04\n  test loss: 4.70e+04\n  test metric: []\n\n'train' took 48.142878 s\n\nCompiling model...\n'compile' took 0.010029 s\n\nWarning: epochs is deprecated and will be removed in a future version. Use iterations instead.\nTraining model...\n\nPresumed Alpha\n<tf.Variable 'Variable:0' shape=() dtype=float32>\nPresumed Alpha\n<tf.Variable 'Variable:0' shape=() dtype=float32>\nStep      Train loss                                            Test loss                                             Test metric\n9000      [5.27e+02, 4.58e-03, 1.21e+01, 5.20e+00, 4.67e+04]    [4.88e+02, 4.58e-03, 1.21e+01, 5.20e+00, 4.67e+04]    []  \n9000 [3.27e-03]\n9000 [1.00e+00]\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1724115939.604227      34 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"10000     [2.91e+02, 3.87e-03, 1.20e+01, 5.41e+00, 4.66e+04]    [2.62e+02, 3.87e-03, 1.20e+01, 5.41e+00, 4.66e+04]    []  \n10000 [3.41e-03]\n10000 [1.00e+00]\n\nBest model at step 10000:\n  train loss: 4.69e+04\n  test loss: 4.69e+04\n  test metric: []\n\n'train' took 47.661833 s\n\nCompiling model...\n'compile' took 0.008113 s\n\nWarning: epochs is deprecated and will be removed in a future version. Use iterations instead.\nTraining model...\n\nPresumed Alpha\n<tf.Variable 'Variable:0' shape=() dtype=float32>\nPresumed Alpha\n<tf.Variable 'Variable:0' shape=() dtype=float32>\nStep      Train loss                                            Test loss                                             Test metric\n10000     [2.91e+02, 3.87e-03, 1.20e+01, 5.41e+00, 4.66e+04]    [2.62e+02, 3.87e-03, 1.20e+01, 5.41e+00, 4.66e+04]    []  \n10000 [3.41e-03]\n10000 [1.00e+00]\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1724115987.363168      34 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"11000     [2.91e+02, 4.78e-03, 1.19e+01, 5.57e+00, 4.66e+04]    [2.58e+02, 4.78e-03, 1.19e+01, 5.57e+00, 4.66e+04]    []  \n11000 [3.41e-03]\n11000 [1.00e+00]\n\nBest model at step 11000:\n  train loss: 4.69e+04\n  test loss: 4.69e+04\n  test metric: []\n\n'train' took 47.732405 s\n\nCompiling model...\n'compile' took 0.009741 s\n\nWarning: epochs is deprecated and will be removed in a future version. Use iterations instead.\nTraining model...\n\nPresumed Alpha\n<tf.Variable 'Variable:0' shape=() dtype=float32>\nPresumed Alpha\n<tf.Variable 'Variable:0' shape=() dtype=float32>\nStep      Train loss                                            Test loss                                             Test metric\n11000     [2.91e+02, 4.78e-03, 1.19e+01, 5.57e+00, 4.66e+04]    [2.58e+02, 4.78e-03, 1.19e+01, 5.57e+00, 4.66e+04]    []  \n11000 [3.41e-03]\n11000 [1.00e+00]\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1724116035.000232      34 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"12000     [2.77e+02, 3.80e-03, 1.17e+01, 5.73e+00, 4.66e+04]    [2.42e+02, 3.80e-03, 1.17e+01, 5.73e+00, 4.66e+04]    []  \n12000 [3.45e-03]\n12000 [1.00e+00]\n\nBest model at step 12000:\n  train loss: 4.69e+04\n  test loss: 4.68e+04\n  test metric: []\n\n'train' took 47.688499 s\n\nCompiling model...\n'compile' took 0.008196 s\n\nWarning: epochs is deprecated and will be removed in a future version. Use iterations instead.\nTraining model...\n\nPresumed Alpha\n<tf.Variable 'Variable:0' shape=() dtype=float32>\nPresumed Alpha\n<tf.Variable 'Variable:0' shape=() dtype=float32>\nStep      Train loss                                            Test loss                                             Test metric\n12000     [2.77e+02, 3.80e-03, 1.17e+01, 5.73e+00, 4.66e+04]    [2.42e+02, 3.80e-03, 1.17e+01, 5.73e+00, 4.66e+04]    []  \n12000 [3.45e-03]\n12000 [1.00e+00]\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1724116082.720200      34 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"13000     [2.64e+02, 4.23e-03, 1.15e+01, 5.89e+00, 4.65e+04]    [2.32e+02, 4.23e-03, 1.15e+01, 5.89e+00, 4.65e+04]    []  \n13000 [3.51e-03]\n13000 [1.00e+00]\n\nBest model at step 13000:\n  train loss: 4.68e+04\n  test loss: 4.68e+04\n  test metric: []\n\n'train' took 47.700110 s\n\nCompiling model...\n'compile' took 0.008073 s\n\nWarning: epochs is deprecated and will be removed in a future version. Use iterations instead.\nTraining model...\n\nPresumed Alpha\n<tf.Variable 'Variable:0' shape=() dtype=float32>\nPresumed Alpha\n<tf.Variable 'Variable:0' shape=() dtype=float32>\nStep      Train loss                                            Test loss                                             Test metric\n13000     [2.64e+02, 4.23e-03, 1.15e+01, 5.89e+00, 4.65e+04]    [2.32e+02, 4.23e-03, 1.15e+01, 5.89e+00, 4.65e+04]    []  \n13000 [3.51e-03]\n13000 [1.00e+00]\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1724116130.426547      34 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"14000     [2.41e+02, 4.01e-03, 1.08e+01, 6.27e+00, 4.65e+04]    [2.07e+02, 4.01e-03, 1.08e+01, 6.27e+00, 4.65e+04]    []  \n14000 [3.51e-03]\n14000 [1.00e+00]\n\nBest model at step 14000:\n  train loss: 4.67e+04\n  test loss: 4.67e+04\n  test metric: []\n\n'train' took 47.680003 s\n\nCompiling model...\n'compile' took 0.008207 s\n\nWarning: epochs is deprecated and will be removed in a future version. Use iterations instead.\nTraining model...\n\nPresumed Alpha\n<tf.Variable 'Variable:0' shape=() dtype=float32>\nPresumed Alpha\n<tf.Variable 'Variable:0' shape=() dtype=float32>\nStep      Train loss                                            Test loss                                             Test metric\n14000     [2.41e+02, 4.01e-03, 1.08e+01, 6.27e+00, 4.65e+04]    [2.07e+02, 4.01e-03, 1.08e+01, 6.27e+00, 4.65e+04]    []  \n14000 [3.51e-03]\n14000 [1.00e+00]\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1724116178.748869      34 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"15000     [2.27e+02, 3.60e-03, 1.08e+01, 6.48e+00, 4.64e+04]    [2.15e+02, 3.60e-03, 1.08e+01, 6.48e+00, 4.64e+04]    []  \n15000 [3.67e-03]\n15000 [1.00e+00]\n\nBest model at step 15000:\n  train loss: 4.67e+04\n  test loss: 4.66e+04\n  test metric: []\n\n'train' took 48.251574 s\n\nCompiling model...\n'compile' took 0.008301 s\n\nWarning: epochs is deprecated and will be removed in a future version. Use iterations instead.\nTraining model...\n\nPresumed Alpha\n<tf.Variable 'Variable:0' shape=() dtype=float32>\nPresumed Alpha\n<tf.Variable 'Variable:0' shape=() dtype=float32>\nStep      Train loss                                            Test loss                                             Test metric\n15000     [2.27e+02, 3.60e-03, 1.08e+01, 6.48e+00, 4.64e+04]    [2.15e+02, 3.60e-03, 1.08e+01, 6.48e+00, 4.64e+04]    []  \n15000 [3.67e-03]\n15000 [1.00e+00]\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1724116226.211750      34 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"16000     [4.80e+02, 6.96e-03, 1.05e+01, 6.48e+00, 4.64e+04]    [4.77e+02, 6.96e-03, 1.05e+01, 6.48e+00, 4.64e+04]    []  \n16000 [3.78e-03]\n16000 [1.00e+00]\n\nBest model at step 15000:\n  train loss: 4.67e+04\n  test loss: 4.66e+04\n  test metric: []\n\n'train' took 47.502474 s\n\nCompiling model...\n'compile' took 0.009736 s\n\nWarning: epochs is deprecated and will be removed in a future version. Use iterations instead.\nTraining model...\n\nPresumed Alpha\n<tf.Variable 'Variable:0' shape=() dtype=float32>\nPresumed Alpha\n<tf.Variable 'Variable:0' shape=() dtype=float32>\nStep      Train loss                                            Test loss                                             Test metric\n16000     [4.80e+02, 6.96e-03, 1.05e+01, 6.48e+00, 4.64e+04]    [4.77e+02, 6.96e-03, 1.05e+01, 6.48e+00, 4.64e+04]    []  \n16000 [3.78e-03]\n16000 [1.00e+00]\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1724116273.906798      34 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}