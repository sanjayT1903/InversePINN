{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9563008,"sourceType":"datasetVersion","datasetId":5827901},{"sourceId":194069625,"sourceType":"kernelVersion"}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport torch\nimport torch.nn as nn\nimport matplotlib.pyplot as plt\nimport random\nfrom torch.optim import LBFGS\nfrom tqdm import tqdm\n\nfrom utility_py import *\n\nclass PINNs(nn.Module):\n    def __init__(self, in_dim, hidden_dim, out_dim, num_layer):\n        super(PINNs, self).__init__()\n\n        layers = []\n        for i in range(num_layer-1):\n            if i == 0:\n                layers.append(nn.Linear(in_features=in_dim, out_features=hidden_dim))\n                layers.append(nn.Tanh())\n            else:\n                layers.append(nn.Linear(in_features=hidden_dim, out_features=hidden_dim))\n                layers.append(nn.Tanh())\n\n        layers.append(nn.Linear(in_features=hidden_dim, out_features=out_dim))\n\n        self.linear = nn.Sequential(*layers)\n\n    def forward(self, x, t):\n        src = torch.cat((x,t), dim=-1)\n        return self.linear(src)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-16T02:46:42.748088Z","iopub.execute_input":"2024-10-16T02:46:42.748513Z","iopub.status.idle":"2024-10-16T02:46:44.415671Z","shell.execute_reply.started":"2024-10-16T02:46:42.748473Z","shell.execute_reply":"2024-10-16T02:46:44.414860Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# implementation of PINNsformer\n# paper: PINNsFormer: A Transformer-Based Framework For Physics-Informed Neural Networks\n# link: https://arxiv.org/abs/2307.11833\n# @article{zhao2023pinnsformer,\n#   title={PINNsFormer: A Transformer-Based Framework For Physics-Informed Neural Networks},\n#   author={Zhao, Leo Zhiyuan and Ding, Xueying and Prakash, B Aditya},\n#   journal={arXiv preprint arXiv:2307.11833},\n#   year={2023}\n# }\n\nimport pdb\n\n#from utility_py import get_clones\n\nclass WaveAct(nn.Module):\n    def __init__(self):\n        super(WaveAct, self).__init__() \n        self.w1 = nn.Parameter(torch.ones(1), requires_grad=True)\n        self.w2 = nn.Parameter(torch.ones(1), requires_grad=True)\n\n    def forward(self, x):\n        return self.w1 * torch.sin(x)+ self.w2 * torch.cos(x)\n\nclass FeedForward(nn.Module):\n    def __init__(self, d_model, d_ff=256):\n        super(FeedForward, self).__init__() \n        self.linear = nn.Sequential(*[\n            nn.Linear(d_model, d_ff),\n            WaveAct(),\n            nn.Linear(d_ff, d_ff),\n            WaveAct(),\n            nn.Linear(d_ff, d_model)\n        ])\n\n    def forward(self, x):\n        return self.linear(x)\n\n\nclass EncoderLayer(nn.Module):\n    def __init__(self, d_model, heads):\n        super(EncoderLayer, self).__init__()\n\n        self.attn = nn.MultiheadAttention(embed_dim=d_model, num_heads=heads, batch_first=True)\n        self.ff = FeedForward(d_model)\n        self.act1 = WaveAct()\n        self.act2 = WaveAct()\n        \n    def forward(self, x):\n        x2 = self.act1(x)\n        # pdb.set_trace()\n        x = x + self.attn(x2,x2,x2)[0]\n        x2 = self.act2(x)\n        x = x + self.ff(x2)\n        return x\n\n\nclass DecoderLayer(nn.Module):\n    def __init__(self, d_model, heads):\n        super(DecoderLayer, self).__init__()\n\n        self.attn = nn.MultiheadAttention(embed_dim=d_model, num_heads=heads, batch_first=True)\n        self.ff = FeedForward(d_model)\n        self.act1 = WaveAct()\n        self.act2 = WaveAct()\n\n    def forward(self, x, e_outputs): \n        x2 = self.act1(x)\n        x = x + self.attn(x2, e_outputs, e_outputs)[0]\n        x2 = self.act2(x)\n        x = x + self.ff(x2)\n        return x\n\n\nclass Encoder(nn.Module):\n    def __init__(self, d_model, N, heads):\n        super(Encoder, self).__init__()\n        self.N = N\n        self.layers = get_clones(EncoderLayer(d_model, heads), N)\n        self.act = WaveAct()\n\n    def forward(self, x):\n        for i in range(self.N):\n            x = self.layers[i](x)\n        return self.act(x)\n\nclass Decoder(nn.Module):\n    def __init__(self, d_model, N, heads):\n        super(Decoder, self).__init__()\n        self.N = N\n        self.layers = get_clones(DecoderLayer(d_model, heads), N)\n        self.act = WaveAct()\n        \n    def forward(self, x, e_outputs):\n        for i in range(self.N):\n            x = self.layers[i](x, e_outputs)\n        return self.act(x)\n\n\n\nclass PINNsformer(nn.Module):\n    def __init__(self, d_out, d_model, d_hidden, N, heads):\n        super(PINNsformer, self).__init__()\n\n        self.linear_emb = nn.Linear(2, d_model)\n\n        self.encoder = Encoder(d_model, N, heads)\n        self.decoder = Decoder(d_model, N, heads)\n        self.linear_out = nn.Sequential(*[\n            nn.Linear(d_model, d_hidden),\n            WaveAct(),\n            nn.Linear(d_hidden, d_hidden),\n            WaveAct(),\n            nn.Linear(d_hidden, d_out)\n        ])\n\n    def forward(self, x, t):\n        src = torch.cat((x,t), dim=-1)\n        src = self.linear_emb(src)\n\n        e_outputs = self.encoder(src)\n        d_output = self.decoder(src, e_outputs)\n        output = self.linear_out(d_output)\n        # pdb.set_trace()\n        # raise Exception('stop')\n        return output","metadata":{"execution":{"iopub.status.busy":"2024-10-16T02:46:44.417231Z","iopub.execute_input":"2024-10-16T02:46:44.417620Z","iopub.status.idle":"2024-10-16T02:46:44.440874Z","shell.execute_reply.started":"2024-10-16T02:46:44.417588Z","shell.execute_reply":"2024-10-16T02:46:44.439893Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"gamma_2_AC = 0.01\ngamma_1 = 10e-6\nprint(gamma_1)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-16T02:46:44.441867Z","iopub.execute_input":"2024-10-16T02:46:44.442155Z","iopub.status.idle":"2024-10-16T02:46:44.455076Z","shell.execute_reply.started":"2024-10-16T02:46:44.442124Z","shell.execute_reply":"2024-10-16T02:46:44.454170Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"1e-05\n","output_type":"stream"}]},{"cell_type":"code","source":"seed = 1\nnp.random.seed(seed)\nrandom.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.cuda.is_available() \n\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nprint(device)\nstep_size = 1e-4","metadata":{"execution":{"iopub.status.busy":"2024-10-16T02:46:44.457531Z","iopub.execute_input":"2024-10-16T02:46:44.458199Z","iopub.status.idle":"2024-10-16T02:46:44.489883Z","shell.execute_reply.started":"2024-10-16T02:46:44.458155Z","shell.execute_reply":"2024-10-16T02:46:44.489067Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"cuda:0\n","output_type":"stream"}]},{"cell_type":"code","source":"\nres, b_left, b_right, b_upper, b_lower = get_data([-1, 1], [0, 1], 51, 51)\nres_test, _, _, _, _ = get_data([-1, 1], [0, 1], 101, 101)\n\n# Define the initial condition for u(x, 0)\n#def u_init(x):\n   \n    #return np.sin(n * np.pi * x / L)\n#print(res[:, 0])\n\n# Apply the initial condition to the spatial points at t=0\n#init_cond = u_init(res[:, 0])  # Assuming t=0 corresponds to the first time point\n\n# Extend time sequence\nres = make_time_sequence(res, num_step=5, step=1e-4)\nb_left = make_time_sequence(b_left, num_step=5, step=1e-4)\nb_right = make_time_sequence(b_right, num_step=5, step=1e-4)\nb_upper = make_time_sequence(b_upper, num_step=5, step=1e-4)\nb_lower = make_time_sequence(b_lower, num_step=5, step=1e-4)\nres_test = make_time_sequence(res_test, num_step=5, step=1e-4)\nres_test = torch.tensor(res_test, dtype=torch.float32, requires_grad=True).to(device)\n\n# Convert to PyTorch tensors\nres = torch.tensor(res, dtype=torch.float32, requires_grad=True).to(device)\nb_left = torch.tensor(b_left, dtype=torch.float32, requires_grad=True).to(device)\nb_right = torch.tensor(b_right, dtype=torch.float32, requires_grad=True).to(device)\nb_upper = torch.tensor(b_upper, dtype=torch.float32, requires_grad=True).to(device)\nb_lower = torch.tensor(b_lower, dtype=torch.float32, requires_grad=True).to(device)\n\n# Initial condition as tensor\n#init_cond = torch.tensor(init_cond, dtype=torch.float32).to(device)\n\n# Separate spatial (x) and temporal (t) components\nx_res, t_res = res[:, :, 0:1], res[:, :, 1:2]\nx_left, t_left = b_left[:, :, 0:1], b_left[:, :, 1:2]\nx_right, t_right = b_right[:, :, 0:1], b_right[:, :, 1:2]\nx_upper, t_upper = b_upper[:,:,0:1], b_upper[:,:,1:2]\nx_lower, t_lower = b_lower[:,:,0:1], b_lower[:,:,1:2]\n\n\n# Initialize model weights\ndef init_weights(m):\n    if isinstance(m, nn.Linear):\n        torch.nn.init.xavier_uniform_(m.weight)\n        m.bias.data.fill_(0.01)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-16T02:46:44.490931Z","iopub.execute_input":"2024-10-16T02:46:44.491305Z","iopub.status.idle":"2024-10-16T02:46:44.683743Z","shell.execute_reply.started":"2024-10-16T02:46:44.491264Z","shell.execute_reply":"2024-10-16T02:46:44.682744Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"model = PINNsformer(d_out=1, d_hidden=512, d_model=32, N=1, heads=2).to(device)\nimport torch.optim as optimer\nmodel.apply(init_weights)\noptim = LBFGS(model.parameters(), line_search_fn='strong_wolfe')\n#optim = optimer.Adam(model.parameters(), lr=1e-4)\n\nprint(model)\nprint(get_n_params(model))","metadata":{"execution":{"iopub.status.busy":"2024-10-16T02:46:44.684927Z","iopub.execute_input":"2024-10-16T02:46:44.685253Z","iopub.status.idle":"2024-10-16T02:46:45.625142Z","shell.execute_reply.started":"2024-10-16T02:46:44.685221Z","shell.execute_reply":"2024-10-16T02:46:45.624254Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"PINNsformer(\n  (linear_emb): Linear(in_features=2, out_features=32, bias=True)\n  (encoder): Encoder(\n    (layers): ModuleList(\n      (0): EncoderLayer(\n        (attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n        )\n        (ff): FeedForward(\n          (linear): Sequential(\n            (0): Linear(in_features=32, out_features=256, bias=True)\n            (1): WaveAct()\n            (2): Linear(in_features=256, out_features=256, bias=True)\n            (3): WaveAct()\n            (4): Linear(in_features=256, out_features=32, bias=True)\n          )\n        )\n        (act1): WaveAct()\n        (act2): WaveAct()\n      )\n    )\n    (act): WaveAct()\n  )\n  (decoder): Decoder(\n    (layers): ModuleList(\n      (0): DecoderLayer(\n        (attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n        )\n        (ff): FeedForward(\n          (linear): Sequential(\n            (0): Linear(in_features=32, out_features=256, bias=True)\n            (1): WaveAct()\n            (2): Linear(in_features=256, out_features=256, bias=True)\n            (3): WaveAct()\n            (4): Linear(in_features=256, out_features=32, bias=True)\n          )\n        )\n        (act1): WaveAct()\n        (act2): WaveAct()\n      )\n    )\n    (act): WaveAct()\n  )\n  (linear_out): Sequential(\n    (0): Linear(in_features=32, out_features=512, bias=True)\n    (1): WaveAct()\n    (2): Linear(in_features=512, out_features=512, bias=True)\n    (3): WaveAct()\n    (4): Linear(in_features=512, out_features=1, bias=True)\n  )\n)\n453561\n","output_type":"stream"}]},{"cell_type":"code","source":"def get_minibatch(data, batch_index, num_batches=1):\n    \"\"\"\n    Splits the data into `num_batches` parts and returns the part corresponding to `batch_index`.\n    \n    Args:\n    - data: Tensor of shape (N, *, *) where N is the number of data points (could be res, b_left, b_right, etc.)\n    - batch_index: Index of the batch to return (between 0 and num_batches-1)\n    - num_batches: Total number of batches to split the data into (default: 5)\n\n    Returns:\n    - A subset of the data corresponding to the specified batch.\n    \"\"\"\n    total_size = data.size(0)\n    batch_size = total_size // num_batches\n    start_idx = batch_index * batch_size\n    end_idx = start_idx + batch_size\n\n    # Ensure we get all remaining data for the last batch\n    if batch_index == num_batches - 1:\n        end_idx = total_size\n\n    return data[start_idx:end_idx]","metadata":{"execution":{"iopub.status.busy":"2024-10-16T02:46:45.626499Z","iopub.execute_input":"2024-10-16T02:46:45.627046Z","iopub.status.idle":"2024-10-16T02:46:45.633424Z","shell.execute_reply.started":"2024-10-16T02:46:45.626981Z","shell.execute_reply":"2024-10-16T02:46:45.632393Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"#print(x_res)\nloss_recorder=[]\nimport random \nlist1 = [0]\nrandom.choice(list1)\ndef check_nan(tensor, name):\n    if torch.isnan(tensor).any():\n        print(f\"NaNs detected in {name}\")\nloss_track = []\n\n#t_ic = torch.zeros_like(x_right_batch)\nk=0\nbatch_index = 0\nx_res_batch = get_minibatch(x_res, batch_index)\nt_res_batch = get_minibatch(t_res, batch_index)\n\nx_left_batch = get_minibatch(x_left, batch_index)\nt_left_batch = get_minibatch(t_left, batch_index)\nx_right_batch = get_minibatch(x_right, batch_index)            \nt_right_batch = get_minibatch(t_right, batch_index)\n            \nx_upper_batch = get_minibatch(x_upper, batch_index)\nt_upper_batch = get_minibatch(t_upper, batch_index)\nx_lower_batch = get_minibatch(x_lower, batch_index)\nt_lower_batch = get_minibatch(t_lower, batch_index)\nt_ic = torch.zeros_like(x_right_batch)\nerror_finish = False\nerror_finish_threshold = .0005\nfor i in tqdm(range(450)):\n    k+=1\n    if k % 200==0:\n        \n            print(\"progress\")\n            loss_recorder.append('Loss Res: {:4f}, Loss_IC: {:4f}, loss_bc: {:4f}'.format(loss_track[-1][0], loss_track[-1][1], loss_track[-1][2]))\n            \n    def closure():\n        t_ic = torch.zeros_like(x_right_batch)\n        pred_res = model(x_res_batch, t_res_batch)\n        pred_left = model(x_left_batch, t_left_batch) #  Left boundary of the spatial domain (x=0) over all times.\n        pred_right = model(x_right_batch, t_right_batch) # t_right is 1\n        #print(x_right_batch)\n        pred_ic = model(x_right_batch,t_ic )\n        #print(pred_ic)\n        #return\n        pred_upper = model(x_upper_batch, t_upper_batch) #  All spatial points at the final time step (x=1).\n        pred_lower = model(x_lower_batch, t_lower_batch) #  All spatial points at the initial time step (x=-1).\n        pred_res_t0 = pred_res[:, 0, :]\n        #print(t_lower_batch) #LOWER BATCH IS X=-1 Higher is X=1\n#         print(t_right_batch)\n\n\n        u_x = torch.autograd.grad(pred_res, x_res_batch, grad_outputs=torch.ones_like(pred_res), retain_graph=True, create_graph=True)[0]\n        u_xx = torch.autograd.grad(u_x, x_res_batch, grad_outputs=torch.ones_like(u_x), retain_graph=True, create_graph=True)[0]\n        u_t = torch.autograd.grad(pred_res, t_res_batch, grad_outputs=torch.ones_like(pred_res), retain_graph=True, create_graph=True)[0]\n\n#         u_x_left = torch.autograd.grad(pred_left, x_left_batch, grad_outputs=torch.ones_like(pred_left), retain_graph=True, create_graph=True)[0]\n#         u_x_right = torch.autograd.grad(pred_right, x_right_batch, grad_outputs=torch.ones_like(pred_right), retain_graph=True, create_graph=True)[0]\n\n        # Compute u_x at x = -1 and x = 1\n        u_x_lower = torch.autograd.grad(pred_lower, x_lower_batch, grad_outputs=torch.ones_like(pred_lower), retain_graph=True, create_graph=True)[0]\n        u_x_upper = torch.autograd.grad(pred_upper, x_upper_batch, grad_outputs=torch.ones_like(pred_upper), retain_graph=True, create_graph=True)[0]\n\n        \n        check_nan(u_x, 'u_x')\n        check_nan(u_xx, 'u_xx')\n        check_nan(u_t, 'u_t')\n        check_nan(pred_res, 'pred_res')\n        check_nan(pred_ic, 'pred_ic')\n        check_nan(pred_upper, 'pred_upper')\n        check_nan(pred_lower, 'pred_lower')\n       \n        #alpha =a   # thermal diffusivity (can be modified)\n        #1. PDE LOSS eesidual\n        # Compute the first Laplacian (second derivative) of u\n        v = - u_xx\n\n        # Update the first PDE for u using the new variable v\n        interm = gamma_2_AC * (pred_res**3 - pred_res) + gamma_1 * v\n        interm_x = torch.autograd.grad(interm, x_res_batch, grad_outputs=torch.ones_like(pred_res), retain_graph=True, create_graph=True)[0]\n        interm_xx = torch.autograd.grad(interm_x, x_res_batch, grad_outputs=torch.ones_like(interm_x), retain_graph=True, create_graph=True)[0]\n\n        # Compute the loss with the updated system\n        loss_res = torch.mean((u_t - interm_xx)**2)\n\n        # Second PDE for v\n        v_loss = torch.mean((v + u_xx)**2)\n\n        #2. Loss for initial condition\n        #print(pred_ic)\n        initial_condition = -1 * torch.cos(2*torch.pi * x_right_batch)\n        #initial_condition = (x_right_batch**2) * torch.cos(torch.pi * x_right_batch)\n        loss_ic = torch.mean((pred_ic-initial_condition) ** 2)\n        \n        \n        # 3. Boundary conditions: enforce Dirichlet BCs (u(0,t) = u(L,t) = 0)\n        loss_bc_1 = torch.mean((pred_upper - pred_lower) ** 2)\n        loss_bc_2 = torch.mean((u_x_lower - u_x_upper) ** 2)\n        \n        #loss_bc_2 =  torch.mean((pred_left-pred_right) ** 2) \n        loss_bc = torch.mean((loss_bc_1 + loss_bc_2)**2)\n        \n        loss_track.append([loss_res.item(), v_loss.item(),  loss_ic.item(), loss_bc.item()])\n\n        if k < 1000:\n            loss = 10*loss_res + 10*v_loss + 100*loss_ic + loss_bc\n        else:\n            loss = 100*loss_res+ 100*v_loss  + 100*loss_ic + loss_bc\n        if k ==1000:\n            print(\"Changing the Loss Function\")\n        #print(loss)\n        #print(loss_track[-1])\n        optim.zero_grad()\n        loss.backward()\n        \n        if loss_res <= error_finish_threshold and loss_ic<= error_finish_threshold and loss_bc<= error_finish_threshold:\n            error_finish = True\n        \n        return loss\n    if error_finish:\n        print(\"finish early\")\n        print(\"Iteration end on\")\n        print(k)\n        break\n    else:\n        optim.step(closure)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-16T02:46:45.634991Z","iopub.execute_input":"2024-10-16T02:46:45.635408Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"  0%|          | 0/1400 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/autograd/graph.py:768: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:135.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n  0%|          | 7/1400 [02:20<7:33:04, 19.52s/it]","output_type":"stream"}]},{"cell_type":"code","source":"print(f\"Length of loss_track: {len(loss_track)}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# optim = optimer.Adam(model.parameters(), lr=1e-4)\n# import random \n# list1 = [0]\n# random.choice(list1)\n# def check_nan(tensor, name):\n#     if torch.isnan(tensor).any():\n#         print(f\"NaNs detected in {name}\")\n# loss_track = []\n\n# #t_ic = torch.zeros_like(x_right_batch)\n# k=0\n# batch_index = 0\n# x_res_batch = get_minibatch(x_res, batch_index)\n# t_res_batch = get_minibatch(t_res, batch_index)\n\n# x_left_batch = get_minibatch(x_left, batch_index)\n# t_left_batch = get_minibatch(t_left, batch_index)\n# x_right_batch = get_minibatch(x_right, batch_index)            \n# t_right_batch = get_minibatch(t_right, batch_index)\n            \n# x_upper_batch = get_minibatch(x_upper, batch_index)\n# t_upper_batch = get_minibatch(t_upper, batch_index)\n# x_lower_batch = get_minibatch(x_lower, batch_index)\n# t_lower_batch = get_minibatch(t_lower, batch_index)\n# t_ic = torch.zeros_like(x_right_batch)\n# for i in tqdm(range(10)):\n#     k+=1\n#     if k == 200:\n    \n#             print(\"progress\")\n#             k=0\n#     def closure():\n#         t_ic = torch.zeros_like(x_right_batch)\n#         pred_res = model(x_res_batch, t_res_batch)\n#         pred_left = model(x_left_batch, t_left_batch) #  Left boundary of the spatial domain (x=0) over all times.\n#         pred_right = model(x_right_batch, t_right_batch) # t_right is 1\n#         #print(x_right_batch)\n#         pred_ic = model(x_right_batch,t_ic )\n#         #print(pred_ic)\n#         #return\n#         pred_upper = model(x_upper_batch, t_upper_batch) #  All spatial points at the final time step (x=1).\n#         pred_lower = model(x_lower_batch, t_lower_batch) #  All spatial points at the initial time step (x=-1).\n#         pred_res_t0 = pred_res[:, 0, :]\n#         #print(t_lower_batch) #LOWER BATCH IS X=-1 Higher is X=1\n# #         print(t_right_batch)\n\n\n#         u_x = torch.autograd.grad(pred_res, x_res_batch, grad_outputs=torch.ones_like(pred_res), retain_graph=True, create_graph=True)[0]\n#         u_xx = torch.autograd.grad(u_x, x_res_batch, grad_outputs=torch.ones_like(u_x), retain_graph=True, create_graph=True)[0]\n#         u_t = torch.autograd.grad(pred_res, t_res_batch, grad_outputs=torch.ones_like(pred_res), retain_graph=True, create_graph=True)[0]\n\n# #         u_x_left = torch.autograd.grad(pred_left, x_left_batch, grad_outputs=torch.ones_like(pred_left), retain_graph=True, create_graph=True)[0]\n# #         u_x_right = torch.autograd.grad(pred_right, x_right_batch, grad_outputs=torch.ones_like(pred_right), retain_graph=True, create_graph=True)[0]\n\n#         # Compute u_x at x = -1 and x = 1\n#         u_x_lower = torch.autograd.grad(pred_lower, x_lower_batch, grad_outputs=torch.ones_like(pred_lower), retain_graph=True, create_graph=True)[0]\n#         u_x_upper = torch.autograd.grad(pred_upper, x_upper_batch, grad_outputs=torch.ones_like(pred_upper), retain_graph=True, create_graph=True)[0]\n\n        \n#         check_nan(u_x, 'u_x')\n#         check_nan(u_xx, 'u_xx')\n#         check_nan(u_t, 'u_t')\n#         check_nan(pred_res, 'pred_res')\n#         check_nan(pred_ic, 'pred_ic')\n#         check_nan(pred_upper, 'pred_upper')\n#         check_nan(pred_lower, 'pred_lower')\n       \n#         #alpha =a   # thermal diffusivity (can be modified)\n#         #1. PDE LOSS eesidual\n#         loss_res =torch.mean((u_t - gamma_1 * u_xx + gamma_2_AC * (pred_res**3 - pred_res))**2)\n\n#         #2. Loss for initial condition\n#         #print(pred_ic)\n#         initial_condition = (x_right_batch**2) * torch.sin(2*torch.pi * x_right_batch)\n#         #initial_condition = (x_right_batch**2) * torch.cos(torch.pi * x_right_batch)\n#         loss_ic = torch.mean((pred_ic-initial_condition) ** 2)\n        \n        \n#         # 3. Boundary conditions: enforce Dirichlet BCs (u(0,t) = u(L,t) = 0)\n#         loss_bc_1 = torch.mean((pred_upper - pred_lower) ** 2)\n#         loss_bc_2 = torch.mean((u_x_lower - u_x_upper) ** 2)\n        \n#         #loss_bc_2 =  torch.mean((pred_left-pred_right) ** 2) \n#         loss_bc = torch.mean((loss_bc_1 + loss_bc_2)**2)\n        \n#         loss_track.append([loss_res.item(), loss_ic.item(), loss_bc.item()])\n\n#         loss = 10*loss_res + 100*loss_ic + loss_bc\n#         #print(loss)\n#         #print(loss_track[-1])\n#         optim.zero_grad()\n#         loss.backward()\n        \n#         return loss\n    \n#     optim.step(closure)\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Loss Res: {:4f}, Loss_mu: {:4f}, Loss_IC: {:4f}, loss_bc: {:4f}'.format(loss_track[-1][0], loss_track[-1][1], loss_track[-1][2], loss_track[-1][3]))\nprint('Train Loss: {:4f}'.format(np.sum(loss_track[-1])))\n\ntorch.save(model.state_dict(), './1dreaction_pinnsformer.pt')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n# Convert loss_track to a NumPy array for easier slicing\nloss_track = np.array(loss_track)\n\n# Extract each loss component\nresidual_loss = loss_track[:, 0]\ninitial_condition_loss = loss_track[:, 2]\nmu_decouple_loss = loss_track[:, 1]\nboundary_condition_loss = loss_track[:, 3]\n\n# Plot loss components\nplt.figure(figsize=(12, 6))\nplt.plot(residual_loss, label='Residual Loss', color='r')\nplt.plot(boundary_condition_loss, label='Boundary Condition Loss', color='g')\nplt.plot(initial_condition_loss, label='Initial Condition Loss', color='b')\nplt.plot(mu_decouple_loss, label='Decouple Loss', color='y')\nplt.xlabel('Iteration')\nplt.ylabel('Loss')\nplt.title('Loss Components During Optimization')\nplt.legend()\nplt.grid(True)\n\nplt.show()\nplt.savefig('./1dCALoss.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Move the tensor to CPU and detach it from the computation graph before using NumPy\n# res_test = make_time_sequence(res_test, num_step=5, step=1e-4)\n# res_test = torch.tensor(res_test, dtype=torch.float32, requires_grad=True).to(device)\nx_test, t_test = res_test[:,:,0:1], res_test[:,:,1:2]\nprint(res.shape)\nprint(x_test.shape)\nprint(x_res.shape)\n\n# Predict using the model\nwith torch.no_grad():\n    pred = model(x_test, t_test)[:, 0:1]\n    pred = pred.cpu().detach().numpy()  # Move to CPU before converting to NumPy\n\n# Reshape the prediction to fit 101x101 grid (space and time)\npred = pred.reshape(101, 101)\n\n# Visualization of predicted solution u(x,t)\nplt.figure(figsize=(4, 3))\nplt.imshow(pred, extent=[0, 1, -1, 1], aspect='auto')\nplt.xlabel('t')\nplt.ylabel('x')\nplt.title('Predicted u(x,t) - 1D Allen Cahn Equation')\nplt.colorbar()\nplt.tight_layout()\nplt.savefig('./1dheat_pinnsformer_pred.png')\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Move the tensor to CPU and detach it from the computation graph before using NumPy\n# res_test = make_time_sequence(res_test, num_step=5, step=1e-4)\n# res_test = torch.tensor(res_test, dtype=torch.float32, requires_grad=True).to(device)\nx_test, t_test = res_test[:, :, 0:1], res_test[:, :, 1:2]\nprint(res.shape)\nprint(x_test.shape)\nprint(x_res.shape)\n\n# Predict using the model\nwith torch.no_grad():\n    pred = model(x_test, t_test)[:, 0:1]\n    pred = pred.cpu().detach().numpy()  # Move to CPU before converting to NumPy\n\n# Reshape the prediction to fit 101x101 grid (space and time)\npred = pred.reshape(101, 101)\n\n# Rotate the prediction 90 degrees to the left\npred = np.rot90(pred, k=1)  # k=1 rotates 90 degrees counterclockwise\n\n# Visualization of predicted solution u(x,t)\nplt.figure(figsize=(4, 3))\nplt.imshow(pred, extent=[0, 1, -1, 1], aspect='auto')\nplt.xlabel('t')\nplt.ylabel('x')\nplt.title('Predicted u(x,t) - 1D Allen Cahn Equation')\nplt.colorbar()\nplt.tight_layout()\nplt.savefig('./1dheat_pinnsformer_pred_rotated.png')\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport torch\nimport matplotlib.pyplot as plt\n\n# Create the x grid (spatial domain) and select specific time steps for visualization\nx_values = np.linspace(-1, 1, 101)  # Spatial domain from -1 to 1 with 101 points\ntime_steps = [0.0, 0.25, 0.75, 1.0]  # The time steps you want to visualize\ntime_steps = [0.0] \n# Plot the predicted solutions at specific time steps\nfig, axes = plt.subplots(1, 4, figsize=(16, 4), sharey=True)\n\nfor idx, t in enumerate(time_steps):\n    # Extract the prediction for the current time step 't'\n    x_test_tensor = torch.tensor(x_values, dtype=torch.float32).unsqueeze(1).to(device)\n    t_test_tensor = torch.tensor(np.full_like(x_values, t), dtype=torch.float32).unsqueeze(1).to(device)\n\n    with torch.no_grad():\n        pred_u = model(x_test_tensor, t_test_tensor).cpu().numpy()  # Predicted u(x, t) from the model\n#         print(pred_u)\n#         print(x_test_tensor.shape)\n#         print(t_test_tensor)\n    # Plotting predicted solutions only\n    axes[idx].plot(x_values, pred_u, 'r--', label='Prediction')  # Predicted solution in red dashed line\n    axes[idx].set_title(f'$t={t}$')\n    axes[idx].set_xlabel('$x$')\n    axes[idx].set_xlim([-1, 1])\n    axes[idx].set_ylim([-1, 1])\n    axes[idx].legend()\n\naxes[0].set_ylabel('$u(t,x)$')\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy.io import loadmat\ndef gen_testdata():\n    data = loadmat(\"/kaggle/input/allen-cahn/Allen_Cahn.mat\")\n\n    t = data[\"t\"]\n    x = data[\"x\"]\n    u = data[\"u\"]\n\n    dt = dx = 0.01\n    xx, tt = np.meshgrid(x, t)\n    X = np.vstack((np.ravel(xx), np.ravel(tt))).T\n    y = u.flatten()[:, None]\n    return X, y\n\nX, y_true = gen_testdata()\n\n# Move the tensor to CPU and detach it from the computation graph before using NumPy\n# res_test = make_time_sequence(res_test, num_step=5, step=1e-4)\n# res_test = torch.tensor(res_test, dtype=torch.float32, requires_grad=True).to(device)\n\n# Reshape the prediction to fit 101x101 grid (space and time)\npred = pred.reshape(101, 101)\n\n\nplt.figure(figsize=(4, 3))\nplt.imshow(X, extent=[0, 1, -1, 1], aspect='auto')\nplt.xlabel('t')\nplt.ylabel('x')\nplt.title('Predicted u(x,t) - 1D Allen Cahn Equation')\nplt.colorbar()\nplt.tight_layout()\nplt.savefig('./1dheat_pinnsformer_pred.png')\nplt.show()\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(loss_recorder)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}